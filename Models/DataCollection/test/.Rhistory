tryCatch({x+1},error=function(e){show("tos")})
tryCatch({x+1},error=function(e){return("tos")})
tryCatch({x+1},error=function(e){return(2)})
tryCatch({x+1},error=function(e){res=2})
res
library(raster)
help("focal")
strsplit("1998;2008;2554")
strsplit("1998;2008;2554",";")
strsplit("1998;2008;2554",";")[[1]]
kwNum = 100000
yearRange=c(1976,1977,1978,1979,1980)
year = paste0(as.character(yearRange[1]),"-",as.character(yearRange[length(yearRange)]))
paste0('relevant.relevant_',year,'_full_',kwNum)
paste0('relevant.relevant_',year,'_full_',kwNum)
5*6*3*10*5
5*6*3*10*5*3
5*6*3*10*5*3*20
5*6*3*10*5*7*20
getwd()
pop = load('Data/GibratSim/countriesPop.RData')
pop
CHina
China
library(dplyr)
as.tbl(China)
China[9000:9100,]
as.tbl(China_Historic)
mmax(China$`2010`)
max(China$`2010`)
hist(China$`2010`,breaks=500)
library(ggplot2)
g=ggplot(China)
d=data.frame()
for(j in 5:8){
d=rbind(d,cbind(sort(China[,j],decreasing = TRUE),1:nrow(China),rep(colnames(China)[j],nrow(China))))
}
sort(China[,j],decreasing = TRUE)
1:nrow(China)
d=data.frame()
for(j in 5:8){
d=rbind(d,data.frame(sort(China[,j],decreasing = TRUE),1:nrow(China),rep(colnames(China)[j],nrow(China))))
}
nrow(China)
China[,j]
d=data.frame()
for(j in 5:8){
d=rbind(d,data.frame(sort(China[,j],decreasing = TRUE,na.last = TRUE),1:nrow(China),rep(colnames(China)[j],nrow(China))))
}
colnames(d)<-c("size","rank","year")
colnames(d)
dim(d)
g=ggplot(d)
g+geom_point(aes(x=rnake,y=size,colour=year))
g+geom_point(aes(x=rank,y=size,colour=year))
g+geom_point(aes(x=log(rank),y=log(size),colour=year))
help("geom_bar")
192000 * 109 / 200
192000 * 109 / 200 / 3600
192000 * 109 / 200 / 3600 / 10
192000 * 109 / 200 / 3600 / 20
14/1.38
50*49/2
d=read.csv('/Users/Juste/Documents/ComplexSystems/EnergyPrice/Models/DataCollection/test/data/test_all.csv')
d=read.csv('/Users/Juste/Documents/ComplexSystems/EnergyPrice/Models/DataCollection/test/data/test_all.csv',sep=";")
d
head(d)
d=read.csv('/Users/Juste/Documents/ComplexSystems/EnergyPrice/Models/DataCollection/test/data/test_all.csv',sep=";",header=FALSE)
head(d)
head(d,n = 100)
which(d[,2]==0)
which(d[,2]==2)
unique(d[,2])
help(apply)
help(Matrix)
library(Matrix)
help("Matrix")
library(raster)
help("focal")
NCmisc::estimate.memory()
install.packages("NCmisc")
NCmisc::estimate.memory()
library(NCmisc)
help("estimate.memory")
library(kernlab)
#library(plot3D)
##############
# Generate a random density distribution
#    following a scaling law with params alpha>0, Pmax (P_i = Pmax*i^{-\alpha})
#
#  Value :
#     Spatial matrix of distribution values
#
#  Parameters :
#     - gridSize : width of the square grid
#     - N : number of kernels (cities)
#     - alpha : rank-size scaling parameter
#     - proba = TRUE : return a probability distribution
#     - rmin = 0 : minimal radius of cities (uniformaly drawn within rmlin,rmax) ; gridSize/N if 0
#     - rmax = 0 : idem
#     - Pmax = 1 : population of the greatest city (useful if proba == FALSE)
#     - tolThreshold : DEPRECATED
#     - kernel_type = "poisson" : can be "gaussian" (sigma=1/(2*r^2)) or "poisson" (sigma=1/r)
spatializedExpMixtureDensity <- function(gridSize,N,alpha,proba=TRUE,rmin=0,rmax=0,Pmax=1,tolThreshold=0,kernel_type="poisson"){
if(rmin==0){rmin = gridSize/N}
if(rmax==0){rmax = gridSize/N}
# patches of the grid are 1 unit size (in r_min/max units)
grid = matrix(0,gridSize,gridSize)
# matrix of coordinates
coords = matrix(c(c(matrix(rep(1:gridSize,gridSize),nrow=gridSize)),c(matrix(rep(1:gridSize,gridSize),nrow=gridSize,byrow=TRUE))),nrow=gridSize^2)
# first draw param distribs ? not needed
# for exp distribs, P_i = 2pi*d_i*r_i^2
#  -> take P from deterministic distrib ; draw r.
for(i in 1:N){
show(i)
pop_i = Pmax*i^{-alpha}
r_i = runif(1,min=rmin,max=rmax)
d_i = pop_i / (2*pi*(r_i^2))
# find origin of that kernel
#  -> one of points such that : d(bord) > rcut and \forall \vec{x}\in D(rcut),d(\vec{x})<tolThr.
#pot = which(!pseudoClosing(grid>tolThreshold,r_i),arr.ind=TRUE)
#show(length(pot))
#if(length(pot)==0){
#  # Take a point with minimal density ?
#  pot = which(grid==min(grid),arr.ind=TRUE)
#}
# simplify : take deterministiquely (almost, after two exps only two points possible)
# BUT not close to border
#rbord = 2*rmax*log(Pmax/tolThreshold)
rbord = 2*rmax
# random center
if(max(grid)==0){
# random if no center yet
center = matrix(runif(2,min=rbord+1,max=gridSize-rbord),nrow=1)
}
else {
# else find min pop area not too close to border
pot = which(grid==min(grid[(rbord+1):(gridSize-rbord),(rbord+1):(gridSize-rbord)]),arr.ind=TRUE)
row = sample(nrow(pot),1)
center = matrix(pot[row,],nrow=1)
}
# add kernel : use kernlab laplace kernel or other
if(kernel_type=="poisson"){ker=laplacedot(sigma=1/r_i)}
if(kernel_type=="gaussian"){ker=rbfdot(sigma=1/(2*r_i^2))}
#if(kernel_type="quadratic"){ker=} # is quad kernel available ?
grid = grid + (d_i * matrix(kernelMatrix(kernel=laplacedot(sigma=1/r_i),x=coords,y=center),nrow=gridSize))
}
if(proba==TRUE){grid = grid / sum(grid)}
return(grid)
}
##
# Dirty morpho mat closing
#   used to determine empirical scaling exponent
pseudoClosing <- function(mat,rcut){
res=matrix(mat,nrow=nrow(mat))
for(i in 1:nrow(mat)){
for(j in 1:ncol(mat)){
if(i>rcut&&i<nrow(mat)-rcut+1&&j>rcut&&j<ncol(mat)-rcut+1){
# dirty that way - should be quicker with convol.
# furthermore Manhattan distance, not best solution for distribs symmetric by rotation.
if(sum(mat[(i-rcut):(i+rcut),(j-rcut):(j+rcut)])>=1){res[i,j]=TRUE}
}else{res[i,j]=TRUE}
}
}
return(res)
}
# test the function
test = spatializedExpMixtureDensity(100,20,0.7)
#persp3D(z=test)
# -> not disgusting
# test the scaling
#
# for counter proportionnal to density.
# cut at threshold, get sizes of each cluster.
# use connexAreas function of morphoAnalysis
# function giving slope as a function of theta
linFit <- function(d,theta){
c = connexAreas(d>theta)
pops = c()
for(i in 1:length(c)){pops=append(pops,sum(d[c[[i]]]))}
x=log(1:length(pops))
y=log(sort(pops,decreasing=TRUE))
return(lm(y~x,data.frame(x,y)))
}
# Empirical scaling exponent log(A_i) = K - alpha log(P_i)
empScalExp <- function(theta,lambda,beta,d){
c = connexAreas(d>theta)
pops = c();amens = c()
for(i in 1:length(c)){
pops=append(pops,sum(d[c[[i]]]))
amens=append(amens,sum(lambda*d[c[[i]]]^beta))
}
x=log(pops)
y=log(amens)
fit = lm(y~x,data.frame(x,y))
return(fit$coefficients[2])
}
#
#slope(test,0.02)
#persp3D(z=d)
#d=spatializedExpMixtureDensity(200,15,5,5,200,0.7,0.001)
#thetas=seq(from=0.01,to=0.2,by=0.005)
# be careful in thresholds, not good connex areas otherwise
# thetas given in proportion
#slopes=c();rsquared=c()
#for(theta in thetas){
#  l=linFit(d,theta*max(d))
#  slopes=append(slopes,l$coefficients[2])
#  rsquared=append(rsquared,summary(l)$adj.r.squared)
#}
#plot(thetas,-slopes)
#plot(thetas,rsquared)
# slope of slopes ?
#lm(-slopes~thetas,data.frame(thetas,slopes))$coefficients[2]
###############
## Morpho funs
###############
library(rlist)
# iterative version
propagate <- function(m,indices,ii,jj,n){
pile = list(c(ii,jj))
while(length(pile)>0){
# unstack first
coords = list.take(pile,1)[[1]] ; pile = list.remove(pile,1);
i=coords[1];j=coords[2];
# update indices
indices[i,j]=n
#stack neighbors of conditions are met
if(i>1){if(indices[i-1,j]==0&&m[i-1,j]==TRUE){pile = list.prepend(pile,c(i-1,j))}}
if(i<nrow(m)){if(indices[i+1,j]==0&&m[i+1,j]==TRUE){pile = list.prepend(pile,c(i+1,j))}}
if(j>1){if(indices[i,j-1]==0&&m[i,j-1]==TRUE){pile = list.prepend(pile,c(i,j-1))}}
if(j<ncol(m)){if(indices[i,j+1]==0&&m[i,j+1]==TRUE){pile = list.prepend(pile,c(i,j+1))}}
}
return(indices)
}
connexAreas <- function(m){
indices <- matrix(data=rep(0,nrow(m)*ncol(m)),nrow=nrow(m),ncol=ncol(m))
maxArea = 0
for(i in 1:nrow(m)){
for(j in 1:ncol(m)){
# if colored but not marked, mark recursively
#   -- necessarily a new area
if(m[i,j]==TRUE&&indices[i,j]==0){
maxArea = maxArea + 1
show(paste("Prop",i,j," - area ",maxArea))
indices <- propagate(m,indices,i,j,maxArea)
}
}
}
# use indices to create list of coordinates
areas = list()
for(a in 1:maxArea){
areas=list.append(areas,which(indices==a))
}
return(areas)
}
spatializedExpMixtureDensity(100,10,1.2)
spatializedExpMixtureDensity(100,2,1.2)
spatializedExpMixtureDensity <- function(gridSize,N,alpha,centerDensity,proba=TRUE,rmin=0,rmax=0,Pmax=1,tolThreshold=0,kernel_type="poisson"){
#if(rmin==0){rmin = gridSize/N}
#if(rmax==0){rmax = gridSize/N}
# patches of the grid are 1 unit size (in r_min/max units)
grid = matrix(0,gridSize,gridSize)
# matrix of coordinates
coords = matrix(c(c(matrix(rep(1:gridSize,gridSize),nrow=gridSize)),c(matrix(rep(1:gridSize,gridSize),nrow=gridSize,byrow=TRUE))),nrow=gridSize^2)
# first draw param distribs ? not needed
# for exp distribs, P_i = 2pi*d_i*r_i^2
#  -> take P from deterministic distrib ; draw r.
for(i in 1:N){
show(i)
pop_i = Pmax*i^{-alpha}
d_i = centerDensity
r_i = sqrt(pop_i/(2*pi*d_i))
#r_i = runif(1,min=rmin,max=rmax)
#d_i = pop_i / (2*pi*(r_i^2))
# find origin of that kernel
#  -> one of points such that : d(bord) > rcut and \forall \vec{x}\in D(rcut),d(\vec{x})<tolThr.
#pot = which(!pseudoClosing(grid>tolThreshold,r_i),arr.ind=TRUE)
#show(length(pot))
#if(length(pot)==0){
#  # Take a point with minimal density ?
#  pot = which(grid==min(grid),arr.ind=TRUE)
#}
# simplify : take deterministiquely (almost, after two exps only two points possible)
# BUT not close to border
#rbord = 2*rmax*log(Pmax/tolThreshold)
#rbord = 2*rmax
# random center
# if(max(grid)==0){
#   # random if no center yet
#   center = matrix(runif(2,min=rbord+1,max=gridSize-rbord),nrow=1)
# }
# else {
#   # else find min pop area not too close to border
#   pot = which(grid==min(grid[(rbord+1):(gridSize-rbord),(rbord+1):(gridSize-rbord)]),arr.ind=TRUE)
#   row = sample(nrow(pot),1)
#   center = matrix(pot[row,],nrow=1)
# }
center = matrix(runif(2,min=1,max=gridSize),nrow=1)
# add kernel : use kernlab laplace kernel or other
#if(kernel_type=="poisson"){ker=laplacedot(sigma=1/r_i)}
#if(kernel_type=="gaussian"){ker=rbfdot(sigma=1/(2*r_i^2))}
#if(kernel_type="quadratic"){ker=} # is quad kernel available ?
grid = grid + (d_i * matrix(kernelMatrix(kernel=laplacedot(sigma=1/r_i),x=coords,y=center),nrow=gridSize))
}
if(proba==TRUE){grid = grid / sum(grid)}
return(grid)
}
spatializedExpMixtureDensity(100,5,1.2,10)
max(spatializedExpMixtureDensity(100,5,1.2,10))
test = spatializedExpMixtureDensity(100,20,0.7,1)
persp3D(z=test)
library(plot3D)
persp3D(z=test)
test = spatializedExpMixtureDensity(100,20,0.7,0.1)
persp3D(z=test)
test = spatializedExpMixtureDensity(50,20,0.7,0.1)
persp3D(z=test)
test = spatializedExpMixtureDensity(50,10,0.7,0.05)
persp3D(z=test)
spatializedExpMixtureDensity <- function(gridSize,N,alpha,centerDensity,proba=TRUE,rmin=0,rmax=0,Pmax=1,tolThreshold=0,kernel_type="poisson"){
#if(rmin==0){rmin = gridSize/N}
#if(rmax==0){rmax = gridSize/N}
# patches of the grid are 1 unit size (in r_min/max units)
grid = matrix(0,gridSize,gridSize)
# matrix of coordinates
coords = matrix(c(c(matrix(rep(1:gridSize,gridSize),nrow=gridSize)),c(matrix(rep(1:gridSize,gridSize),nrow=gridSize,byrow=TRUE))),nrow=gridSize^2)
# first draw param distribs ? not needed
# for exp distribs, P_i = 2pi*d_i*r_i^2
#  -> take P from deterministic distrib ; draw r.
for(i in 1:N){
show(i)
pop_i = Pmax*i^{-alpha}
d_i = centerDensity
r_i = sqrt(pop_i/(2*pi*d_i))
show(r_i)
#r_i = runif(1,min=rmin,max=rmax)
#d_i = pop_i / (2*pi*(r_i^2))
# find origin of that kernel
#  -> one of points such that : d(bord) > rcut and \forall \vec{x}\in D(rcut),d(\vec{x})<tolThr.
#pot = which(!pseudoClosing(grid>tolThreshold,r_i),arr.ind=TRUE)
#show(length(pot))
#if(length(pot)==0){
#  # Take a point with minimal density ?
#  pot = which(grid==min(grid),arr.ind=TRUE)
#}
# simplify : take deterministiquely (almost, after two exps only two points possible)
# BUT not close to border
#rbord = 2*rmax*log(Pmax/tolThreshold)
#rbord = 2*rmax
# random center
# if(max(grid)==0){
#   # random if no center yet
#   center = matrix(runif(2,min=rbord+1,max=gridSize-rbord),nrow=1)
# }
# else {
#   # else find min pop area not too close to border
#   pot = which(grid==min(grid[(rbord+1):(gridSize-rbord),(rbord+1):(gridSize-rbord)]),arr.ind=TRUE)
#   row = sample(nrow(pot),1)
#   center = matrix(pot[row,],nrow=1)
# }
center = matrix(runif(2,min=1,max=gridSize),nrow=1)
# add kernel : use kernlab laplace kernel or other
#if(kernel_type=="poisson"){ker=laplacedot(sigma=1/r_i)}
#if(kernel_type=="gaussian"){ker=rbfdot(sigma=1/(2*r_i^2))}
#if(kernel_type="quadratic"){ker=} # is quad kernel available ?
grid = grid + (d_i * matrix(kernelMatrix(kernel=laplacedot(sigma=1/r_i),x=coords,y=center),nrow=gridSize))
}
if(proba==TRUE){grid = grid / sum(grid)}
return(grid)
}
test = spatializedExpMixtureDensity(50,10,0.7,0.05)
test = spatializedExpMixtureDensity(100,10,0.7,0.05)
test = spatializedExpMixtureDensity(100,10,0.7,0.01)
persp3D(z=test)
test = spatializedExpMixtureDensity(50,10,0.7,0.01)
persp3D(z=test)
test = spatializedExpMixtureDensity(50,10,0.7,0.01)
persp3D(z=test)
test = spatializedExpMixtureDensity(50,10,0.7,0.005)
persp3D(z=test)
library(dplyr)
library(ggplot2)
setwd(paste0(Sys.getenv('CS_HOME'),'/CircularEconomy/CircularEconomy/Results/Exploration'))
#res <- as.tbl(read.csv('20160701_gridlocal/2016_07_01_07_18_26_grid_local.csv'))
res <- as.tbl(read.csv('20160706_grid_gis/2016_07_06_08_36_31_grid_gis_corrected.csv'))
sres = res %>% group_by(distribSd,gravityDecay,overlapThreshold,transportationCost)%>% summarise(
finalTime = mean(finalTime),nwClustCoef=mean(nwClustCoef),nwComponents=mean(nwComponents),
nwInDegree=mean(nwInDegree),nwMeanFlow=mean(nwMeanFlow),nwOutDegree=mean(nwOutDegree),
totalCost=mean(as.numeric(totalCost)),totalWaste=mean(totalWaste)#,
#transportationCost=mean(transportationCost),gravityDecay=mean(gravityDecay),
#distribSd=mean(distribSd),overlapThreshold=mean(overlapThreshold)
)
sres = res %>% group_by(distribSd,gravityDecay,overlapThreshold,transportationCost)%>% summarise(
finalTime = mean(finalTime),nwClustCoef=mean(nwClustCoef),nwComponents=mean(nwComponents),
nwInDegree=mean(nwInDegree),nwMeanFlow=mean(nwMeanFlow),nwOutDegree=mean(nwOutDegree),
totalCost=mean(as.numeric(totalCost)),totalWaste=mean(totalWaste),count=n()#,
#transportationCost=mean(transportationCost),gravityDecay=mean(gravityDecay),
#distribSd=mean(distribSd),overlapThreshold=mean(overlapThreshold)
)
sres$count
indics = c("finalTime","nwClustCoef","nwComponents","nwInDegree","nwMeanFlow","nwOutDegree","totalCost","totalWaste")
g = ggplot(sres,aes(x=totalWaste,y=totalCost,color=gravityDecay))
g+geom_point(size=0.5)+facet_grid(transportationCost~distribSd,scales = "free")
unique(sres$overlapThreshold)
g = ggplot(sres,aes(x=totalWaste,y=totalCost,color=overlapThreshold))
g+geom_point(size=0.5)+facet_grid(transportationCost~distribSd,scales = "free")
g = ggplot(sres[sres$distribSd==0.05&sres$transportationCost==1,],aes(x=totalWaste,y=totalCost,color=overlapThreshold))
g+geom_point(size=0.5)
g+geom_point(size=2)
g = ggplot(sres[sres$distribSd==0.05&sres$transportationCost==1,],
aes(x=totalWaste,y=totalCost,color=distribSd))
g+geom_point(size=2)
g = ggplot(sres[sres$distribSd==0.05&sres$transportationCost==1,],
aes(x=totalWaste,y=totalCost,color=gravityDecay))
g+geom_point(size=2)
g = ggplot(sres[sres$distribSd==0.05&sres$transportationCost==4,],
aes(x=totalWaste,y=totalCost,color=gravityDecay))
g+geom_point(size=2)
g = ggplot(sres[sres$distribSd==0.05&sres$transportationCost==3,],
aes(x=totalWaste,y=totalCost,color=gravityDecay))
g+geom_point(size=2)
g = ggplot(sres[sres$distribSd==0.1&sres$transportationCost==3,],
aes(x=totalWaste,y=totalCost,color=gravityDecay))
g+geom_point(size=2)
g = ggplot(sres[sres$distribSd==0.25&sres$transportationCost==1,],
aes(x=totalWaste,y=totalCost,color=gravityDecay))
g+geom_point(size=2)
indic="totalCost"
g = ggplot(sres,aes_string(x="overlapThreshold",y="gravityDecay",fill=indic))
indic="totalCost"
g = ggplot(sres,aes_string(x="gravityDecay",y=indic,colour="overlapThrashold",group="overlapThrashold"))
g+geom_line()+facet_grid(transportationCost~distribSd,scales = "free")
g = ggplot(sres,aes_string(x="gravityDecay",y=indic,colour="overlapThreshold",group="overlapThrashold"))
g+geom_line()+facet_grid(transportationCost~distribSd,scales = "free")
g = ggplot(sres,aes_string(x="gravityDecay",y=indic,colour="overlapThreshold",group="overlapThreshold"))
g+geom_line()+facet_grid(transportationCost~distribSd,scales = "free")
g = ggplot(sres[sres$distribSd==0.25&sres$transportationCost==1,],aes_string(x="gravityDecay",y=indic,colour="overlapThreshold",group="overlapThreshold"))
g+geom_line()+facet_grid(transportationCost~distribSd,scales = "free")
res <- as.tbl(read.csv('20160701_gridlocal/2016_07_01_07_18_26_grid_local.csv'))
sres = res %>% group_by(distribSd,gravityDecay,overlapThreshold,transportationCost)%>% summarise(
finalTime = mean(finalTime),nwClustCoef=mean(nwClustCoef),nwComponents=mean(nwComponents),
nwInDegree=mean(nwInDegree),nwMeanFlow=mean(nwMeanFlow),nwOutDegree=mean(nwOutDegree),
totalCost=mean(as.numeric(totalCost)),totalWaste=mean(totalWaste),count=n()#,
#transportationCost=mean(transportationCost),gravityDecay=mean(gravityDecay),
#distribSd=mean(distribSd),overlapThreshold=mean(overlapThreshold)
)
indic="totalCost"
g = ggplot(sres[sres$distribSd==0.25&sres$transportationCost==1,],aes_string(x="gravityDecay",y=indic,colour="overlapThreshold",group="overlapThreshold"))
g+geom_line()+facet_grid(transportationCost~distribSd,scales = "free")
help("chisq.test")
param_points = c(27,182,1717,1533,1178)
sample = res[res$id%in%param_points,]
sample$id=as.character(sample$id)
plotlist = list()
for(indic in c("totalWaste","nwInDegree")){
g=ggplot(sample)
plotlist[[indic]]=g+geom_density(aes_string(x=indic,fill="id",group="id"),alpha=0.4)
}
multiplot(plotlist=plotlist,cols=2)
source(paste0(Sys.getenv("CN_HOME"),'/Models/Utils/R/plots.R'))
plotlist = list()
for(indic in c("totalWaste","nwInDegree")){
g=ggplot(sample)
plotlist[[indic]]=g+geom_density(aes_string(x=indic,fill="id",group="id"),alpha=0.4)
}
multiplot(plotlist=plotlist,cols=2)
res <- as.tbl(read.csv('20160701_gridlocal/2016_07_01_07_18_26_grid_local.csv'))
res
sres = res %>% group_by(distribSd,gravityDecay,overlapThreshold,transportationCost)%>% summarise(
finalTime = mean(finalTime),nwClustCoef=mean(nwClustCoef),nwComponents=mean(nwComponents),
nwInDegree=mean(nwInDegree),nwMeanFlow=mean(nwMeanFlow),nwOutDegree=mean(nwOutDegree),
totalCost=mean(as.numeric(totalCost)),totalWaste=mean(totalWaste),count=n()#,
#transportationCost=mean(transportationCost),gravityDecay=mean(gravityDecay),
#distribSd=mean(distribSd),overlapThreshold=mean(overlapThreshold)
)
which(res[,]==sres[1,])
sres
apply(res,1,function(r){r[c(1:3,9,12)]==sres[1,c(1:3,9,12)]})
res[,c(1:3,9,12)]
res[,c(1,3,9,12)]
res <- as.tbl(read.csv('20160706_grid_gis/2016_07_06_08_36_31_grid_gis_corrected.csv'))
sres = res %>% group_by(distribSd,gravityDecay,overlapThreshold,transportationCost)%>% summarise(
finalTime = mean(finalTime),nwClustCoef=mean(nwClustCoef),nwComponents=mean(nwComponents),
nwInDegree=mean(nwInDegree),nwMeanFlow=mean(nwMeanFlow),nwOutDegree=mean(nwOutDegree),
totalCost=mean(as.numeric(totalCost)),totalWaste=mean(totalWaste),count=n()#,
#transportationCost=mean(transportationCost),gravityDecay=mean(gravityDecay),
#distribSd=mean(distribSd),overlapThreshold=mean(overlapThreshold)
)
param_points = c(27,182,1717,1533,1178)
sample = res[res$id%in%param_points,]
sample$id=as.character(sample$id)
plotlist = list()
for(indic in c("totalWaste","nwInDegree")){
g=ggplot(sample)
plotlist[[indic]]=g+geom_density(aes_string(x=indic,fill="id",group="id"),alpha=0.4)
}
multiplot(plotlist=plotlist,cols=2)
names(res)
setwd(paste0(Sys.getenv("CS_HOME"),'/EnergyPrice/Models/DataCollection'))
setwd(paste0(Sys.getenv("CS_HOME"),'/EnergyPrice/Models/DataCollection/test'))
ids <- read.csv('data/test_all.csv')
head(ids)
ids <- read.csv('data/test_all.csv',sep=";",header=FALSE)
ids
nrow(ids)
nrow(ids)/length(which(ids$V2==2))
length(which(ids$V2!=2))
tail(ids)
max(ids$V2)
max(ids$V1)
ids[ids[1]==10,]
